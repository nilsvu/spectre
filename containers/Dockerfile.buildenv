# Distributed under the MIT License.
# See LICENSE.txt for details.

# If you change this file please push a new image to DockerHub so that the
# new image is used. Docker must be run as root on your machine. There are 3
# different images in this Dockerfile. Here is how to build them for x86_64
# (for Apple Silicon, replace linux/amd64 with linux/arm64):
# 1. `dev`
#
#   cd $SPECTRE_HOME
#   docker build --target dev -t sxscollaboration/spectre:dev \
#                 --platform linux/amd64 \
#                 -f ./containers/Dockerfile.buildenv .
#
# 2. `ci` (this should use the `dev` image you just built for most of it)
#
#   cd $SPECTRE_HOME
#   docker build --target ci -t sxscollaboration/spectre:ci \
#                 --platform linux/amd64 \
#                 -f ./containers/Dockerfile.buildenv .
#
# 3. `demo` To build this, it is recommended to first push the `dev` and `ci`
#    images to DockerHub as the `demo` image uses the remote `dev` image.
#
#   docker push sxscollaboration/spectre:dev
#   docker push sxscollaboration/spectre:ci
#
#    To build `demo`, you must be in $SPECTRE_ROOT and there cannot be a
#    directory named `build` in $SPECTRE_ROOT because the image will create
#    this directory (in the container).
#
#   cd $SPECTRE_HOME
#   rm -rf build/
#   docker build --target demo -t sxscollaboration/spectre:demo \
#                 --platform linux/amd64 \
#                 -f ./containers/Dockerfile.buildenv .
#
#    and then to push the `demo` image to DockerHub:
#
#   docker push sxscollaboration/spectre:demo
#
# If you do not have permission to push to DockerHub please coordinate with
# someone who does. Since changes to this image effect our testing
# infrastructure it is important all changes be carefully reviewed.
#
FROM ubuntu:22.04 AS base

# See
# https://docs.docker.com/engine/reference/builder/#automatic-platform-args-in-the-global-scope
# for how TARGETARCH is defined.
ARG TARGETARCH

# Install required packages for SpECTRE
#
# We intentionally don't install libboost-all-dev because that installs
# Boost.MPI, which installs OpenMPI into the container. When MPI is
# installed inside the container it makes it very difficult to use
# Singularity on HPC systems to interface with the system MPI library.
# The system MPI libraries are usually configured to take advantage of
# InfiniBand or various other networking layers.
RUN apt-get update -y \
    && apt-get install -y gcc-11 g++-11 gfortran-11 \
                          gdb git ninja-build autoconf automake \
                          bison flex \
                          libopenblas-dev liblapack-dev \
                          libgsl-dev \
                          clang-14 clang-format-14 clang-tidy-14 \
                          lld \
                          wget libncurses-dev \
                          cmake ccache lcov \
                          libboost-dev libboost-program-options-dev \
                          libboost-thread-dev libboost-tools-dev libssl-dev \
                          doxygen \
                          libhdf5-dev hdf5-tools \
                          libarpack2-dev libsharp-dev libyaml-cpp-dev \
                          libxsimd-dev

# Install libc++ and jemalloc
# The second `apt-get update` is to ensure that anything that depends on
# libc++-dev is properly found. This was an issue on older versions of Ubuntu
# but might be fixed in the package manager now. To minimize changes, we are
# leaving the update call in for now.
RUN apt-get update -y \
    && apt-get install -y libc++-dev libc++1 libc++abi-dev \
    && apt-get update -y \
    && apt-get install -y libjemalloc2 libjemalloc-dev

# Install Python packages
# We only install packages that are needed by the build system (e.g. to compile
# Python bindings or build documentation) or used by Python code that is
# unit-tested. Any other packages can be installed on-demand.
# - We use python-is-python3 because on Ubuntu 20.04 /usr/bin/python was removed
#   to aid in tracking down anything that depends on python 2. However, many
#   scripts use `/usr/bin/env python` to find python so restore it.
COPY support/Python/requirements.txt requirements.txt
COPY support/Python/dev_requirements.txt dev_requirements.txt
RUN apt-get update -y \
    && apt-get install -y python3-pip python-is-python3 \
    && pip3 --no-cache-dir install pybind11~=2.6.1 \
    && pip3 --no-cache-dir install -r requirements.txt -r dev_requirements.txt \
    && rm requirements.txt dev_requirements.txt

# Enable bash-completion by installing it and then adding it to the .bashrc file
RUN apt-get update -y \
    && apt-get install -y bash-completion \
    && printf "if [ -f /etc/bash_completion ] && ! shopt -oq posix; then\n\
    . /etc/bash_completion\nfi\n\n" >> /root/.bashrc

# Install software that we can't install through apt. We have to distinguish
# between different architectures for many of those.
FROM base AS base-amd64
ENV CHARM_ARCH=x86_64
ENV TEX_ARCH=x86_64

FROM base AS base-arm64
ENV CHARM_ARCH=arm8
ENV TEX_ARCH=aarch64

FROM base-${TARGETARCH} AS dev
ARG TARGETARCH

ARG PARALLEL_MAKE_ARG=-j2
ARG DEBIAN_FRONTEND=noninteractive

# We install dependencies not available through apt manually rather than using
# Spack since Spack ends up building a lot of dependencies from scratch
# that we don't need. Thus, not building the deps with Spack reduces total
# build time of the Docker image.
# - Blaze
RUN wget https://bitbucket.org/blaze-lib/blaze/downloads/blaze-3.8.tar.gz -O blaze.tar.gz \
    && tar -xzf blaze.tar.gz \
    && mv blaze-* blaze \
    && mv blaze/blaze /usr/local/include \
    && rm -rf blaze*
# - Brigand
RUN git clone https://github.com/edouarda/brigand.git \
    && mv brigand/include/brigand /usr/local/include \
    && rm -rf brigand
# - Catch2
RUN wget https://github.com/catchorg/Catch2/archive/refs/tags/v3.4.0.tar.gz -O catch.tar.gz \
    && tar -xzf catch.tar.gz && rm catch.tar.gz \
    && mv Catch2-* Catch2 \
    && cd Catch2 \
    && cmake -B build -D BUILD_TESTING=OFF \
        -D CMAKE_POSITION_INDEPENDENT_CODE=ON \
    && cd build \
    && make $PARALLEL_MAKE_ARG install \
    && cd ../.. && rm -rf Catch2
# - LibXSMM
RUN if [ "$TARGETARCH" = "arm64" ] ; then \
        git clone --single-branch --branch main --depth 1 \
            https://github.com/libxsmm/libxsmm.git libxsmm \
        && cd libxsmm \
        && make $PARALLEL_MAKE_ARG PREFIX=/usr/local/ PLATFORM=1 install \
        && cd .. \
        && rm -rf libxsmm; \
    else \
        wget https://github.com/hfp/libxsmm/archive/1.16.1.tar.gz \
            -O libxsmm.tar.gz \
        && tar -xzf libxsmm.tar.gz \
        && mv libxsmm-* libxsmm \
        && cd libxsmm \
        && make $PARALLEL_MAKE_ARG PREFIX=/usr/local/ install \
        && cd .. \
        && rm -rf libxsmm libxsmm.tar.gz; \
    fi

# Update ld cache to find shared libs in /usr/local/lib/
RUN ldconfig

WORKDIR /work
# Download and build the Charm++ version used by SpECTRE
# We check out only a specific branch in order to reduce the repo size.
#
# We remove the `doc` and `example` directories since these aren't useful to us
# in the container and we want to reduce the size of the container. We do NOT
# remove the `tmp` directories inside the Charm++ build directories because
# Charm++ stores non-temporary files (such as headers) that are needed when
# building with Charm++ in the `tmp` directories.
#
# We build  with debug symbols to make debugging Charm++-interoperability
# easier for people, and build with O2 to reduce build size.
RUN wget https://raw.githubusercontent.com/sxs-collaboration/spectre/develop/support/Charm/v7.0.0.patch

RUN git clone --single-branch --branch v7.0.0 --depth 1 \
        https://github.com/UIUC-PPL/charm charm_7_0_0 \
    && cd /work/charm_7_0_0 \
    && git checkout v7.0.0 \
    && git apply /work/v7.0.0.patch \
    && ./build LIBS multicore-linux-${CHARM_ARCH} clang-14 \
      ${PARALLEL_MAKE_ARG} -g -O2 --build-shared \
    && rm -r /work/charm_7_0_0/doc /work/charm_7_0_0/examples
ENV CHARM_ROOT="/work/charm_7_0_0/multicore-linux-${CHARM_ARCH}-clang"

# Set the environment variable SPECTRE_CONTAINER so we can check if we are
# inside a container (0 is true in bash)
ENV SPECTRE_CONTAINER 0

# The singularity containers work better if the locale is set properly
RUN apt-get update -y \
    && apt-get install -y locales language-pack-fi language-pack-en \
    && export LANGUAGE=en_US.UTF-8 \
    && export LANG=en_US.UTF-8 \
    && export LC_ALL=en_US.UTF-8 \
    && locale-gen en_US.UTF-8 \
    && dpkg-reconfigure locales

# Install bibtex for Doxygen bibliography management
# We first install the TeXLive infrastructure according to the configuration in
# support/TeXLive/texlive.profile and then use it to install the bibtex package.
RUN mkdir /work/texlive && cd /work/texlive \
    && wget http://mirror.ctan.org/systems/texlive/tlnet/install-tl-unx.tar.gz \
    && tar -xzf install-tl-unx.tar.gz \
    && rm install-tl-unx.tar.gz \
    && wget https://raw.githubusercontent.com/sxs-collaboration/spectre/develop/support/TeXLive/texlive.profile \
    && install-tl-*/install-tl -profile=texlive.profile \
    && rm -r install-tl-* texlive.profile install-tl.log \
    && /work/texlive/bin/${TEX_ARCH}-linux/tlmgr install bibtex
ENV PATH="${PATH}:/work/texlive/bin/${TEX_ARCH}-linux"

# Remove the apt-get cache in order to reduce image size
RUN apt-get -y clean


# Everything we need to run tests on CI on GitHub.
FROM dev as ci

# When building this image individually, the PARALLEL_MAKE_ARG from above is not
# remembered (and it doesn't hurt to redefine the env variable).
ARG PARALLEL_MAKE_ARG=-j2

# Install all the compilers we are going to test on CI
RUN apt-get update -y \
    && apt-get install -y gcc-9 g++-9 gfortran-9 \
                          gcc-10 g++-10 gfortran-10 \
                          clang-13

# Install minimum required CMake version so that we test compatibility with it
RUN wget https://github.com/Kitware/CMake/releases/download/v3.18.2/cmake-3.18.2-linux-${CMAKE_ARCH}.sh -O cmake-install.sh \
    && sh cmake-install.sh --prefix=/opt/local/cmake/3.18.2 --skip-license \
    && rm cmake-install.sh

# Install OpenMPI
RUN apt-get install -y openmpi-bin

# We build an mpi version of charm (with clang) because many of our production
# environments have charm built with mpi and we should test that.
WORKDIR /work/charm_7_0_0
RUN ./build LIBS mpi-linux-${CHARM_ARCH}-smp clang-14 \
      ${PARALLEL_MAKE_ARG} -g -O2 --build-shared \
    && rm -rf /work/charm_7_0_0/doc /work/charm_7_0_0/examples

# Download and extract the intel Software Development Emulator binaries
WORKDIR /work
RUN wget https://downloadmirror.intel.com/684899/sde-external-9.0.0-2021-11-07-lin.tar.xz -O sde-external.tar.xz \
    && tar -xJf sde-external.tar.xz \
    && mv sde-external-* sde \
    && rm sde-*

# Remove the apt-get cache in order to reduce image size
RUN apt-get -y clean

WORKDIR /work


# We don't inherit from ci because that has lots of unnecessary compilers that
# we don't need and would only increase the size of the image. We inherit from
# the remote image rather than the local dev because it is faster on release
# CI to just pull the remote dev image and build demo rather than having to
# build all of dev and demo combined.
# Instead of basing demo off the remote dev image, we could pre-fetch the dev
# image and then build from the local cache like
# FROM dev AS demo
# Either way works, we just chose to build from remote instead.
FROM sxscollaboration/spectre:dev AS demo
ARG TARGETARCH

# When building this image individually, the PARALLEL_MAKE_ARG from above is not
# remembered (and it doesn't hurt to redefine the env variable).
ARG PARALLEL_MAKE_ARG=-j2

# vim and emacs for editing files
# Also ffmpeg for making movies with paraview output pngs
# paraview needs curl
RUN apt-get update -y \
    && apt-get install -y vim emacs-nox ffmpeg curl

# Install headless paraview so we can run pvserver in the container
# Note: there is no arm64 linux binary of paraview available, so don't
# install paraview when building for Apple Silicon. Apple Silicon users
# should install a binary of ParaView for Mac and move data to be
# visualized outside of the container.
WORKDIR /work
RUN if [ "$TARGETARCH" != "arm64" ] ; then \
    wget -O paraview.tar.gz --no-check-certificate "https://www.paraview.org/paraview-downloads/download.php?submit=Download&version=v5.10&type=binary&os=Linux&downloadFile=ParaView-5.10.1-osmesa-MPI-Linux-Python3.9-x86_64.tar.gz" \
    && tar -xzf paraview.tar.gz \
    && rm paraview.tar.gz \
    && mv ParaView-* /opt/paraview; \
  fi

ENV PATH "/opt/paraview/bin:$PATH"

WORKDIR /work

# We copy the entire SpECTRE repo from the current context so that people can
# edit and rebuild the pre-built executables if they want to experiment with
# editing and building SpECTRE. The executables are chosen because they are the
# ones in the "Hitchhikers's" tutorial for SpECTRE. More executables can be
# added in later if we so desire. We also build python bindings and install
# jupyterlab for other demos and tutorials.
COPY . spectre/

RUN mkdir spectre/build && cd spectre/build \
  && cmake \
    -D CMAKE_C_COMPILER=clang-14 \
    -D CMAKE_CXX_COMPILER=clang++-14 \
    -D CMAKE_Fortran_COMPILER=gfortran-11 \
    -D CMAKE_BUILD_TYPE=Release \
    -D DEBUG_SYMBOLS=OFF \
    -D BUILD_PYTHON_BINDINGS=ON \
    -D MEMORY_ALLOCATOR=SYSTEM \
    .. \
  && make ${PARALLEL_MAKE_ARG} ExportTimeDependentCoordinates3D \
  && make ${PARALLEL_MAKE_ARG} EvolveScalarAdvection2D \
  && make ${PARALLEL_MAKE_ARG} all-pybindings

RUN pip3 --no-cache-dir install jupyterlab

ENV SPECTRE_HOME /work/spectre
ENV PATH $SPECTRE_HOME/build/bin:$PATH
ENV PYTHONPATH $SPECTRE_HOME/build/bin/python:$PYTHONPATH

WORKDIR /work
